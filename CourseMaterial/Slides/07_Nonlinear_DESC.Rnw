\documentclass[xcolor=dvipsnames]{beamer}
% sets the beamer them and color
\usetheme{Madrid}
\usecolortheme[named=Brown]{structure}
% turns off navigation bar
\beamertemplatenavigationsymbolsempty
% allows inclusion of graphics and makes equations larger
\usepackage{graphicx}
\newcommand*{\Scale}[2][4]{\scalebox{#1}{\ensuremath{#2}}}%
% uses my custom bibliography style
\usepackage[authoryear,round]{natbib}
  \bibliographystyle{c:/aaaWork/zGnrlLatex/afs}
  \bibpunct{(}{)}{;}{a}{}{,}
% allows saving and starting a counter across slides
\newcounter{resEnumi}
\newcommand{\saveResEnumi}{\setcounter{resEnumi}{\theenumi}}
\newcommand{\setResEnumi}{\setcounter{enumi}{\theresEnumi}}

<<setup, echo=FALSE, results='hide', message=FALSE, warning=FALSE>>=
#### Some startup R stuff

## load knitr setup specific for beamer
source("C:/aaaWork/zGnrlLatex/knitr_beamer_setup.R")
## set more global defaults
opts_chunk$set(cache=TRUE)

## load packages needed below
library(FSA)
library(FSAdata)
library(nlstools)
library(xtable)
library(fMultivar)      # for 3-D plotting
library(plotrix)        # for plotCI()

## Load data set
data(Croaker2)
crm <- Subset(Croaker2,sex=="M")

## Fit all of the VB models used in this set of slides
# Typical model
vbT <- vbFuns()   # typical parameterization
fitT <- nls(tl~vbT(age,Linf,K,t0),data=crm,start=vbStarts(tl~age,data=crm,type="typical"))
sumT <- summary(fitT,correlation=TRUE)
coefT <- coef(fitT)

## create the transparent black to use in the plots
pclr <- rgb(0,0,0,0.33)

## set random numbers seed for reproducibility
set.seed(13534545)
@



%###############################################################################
%###############################################################################
% Start the document.
\begin{document}

% Make a title slide
\title[Nonlinear Models]{Nonlinear Models \& Von Bertalanffy Growth}
\author{Dr. Derek H. Ogle}
\institute[Northland College]{\normalsize Northland College\\[2\baselineskip]}
\date[Vermont 2014]{Vermont R Workshop\\ Burtlington VT\\ 5-7 March 2014}
\maketitle


%###############################################################################
%###############################################################################
\begin{frame}[fragile]
\frametitle{von Bertalanffy Model -- Typical}

\[\Scale[1.5]{ E[L|t] = L_{\infty}\left(1-e^{-K(t-t_{0})}\right) }\]

\bigskip
where
\begin{itemize}
  \item $E[L|t]$ is the expected (i.e., average) length at time (or age) t,
\end{itemize}
\end{frame}


\begin{frame}[fragile]
\frametitle{von Bertalanffy Model -- Typical}
\begin{itemize}
  \item $L_{\infty}$ is the asymptotic average length.
  \item $t_{0}$ is a modeling artifact.
\end{itemize}

<<vbT, echo=FALSE>>=
plot(tl~age,data=crm,xlab="Age",ylab="Total Length (mm)",pch=16,col=pclr,
     ylim=c(0,470),xlim=c(-2,12),xaxt="n") 
axis(1,seq(0,12,2))
curve(vbT(x,Linf=coef(fitT)),from=-2,to=12,lwd=3,add=TRUE)
# Mark t0 on plot
t0 <- coef(fitT)[3]
lines(c(t0,t0),c(-20,20),lwd=2,lty=3,col="red")
lines(c(-4,-1),c(0,0),lwd=2,lty=3,col="red")
points(t0,0,col="red",pch=19,cex=1.25)
text(t0,-42,expression(t[0]),xpd=TRUE,col="red",cex=1.25)
# Mark Linf on plot
Linf <- coef(fitT)[1]
abline(h=Linf,lwd=2,lty=3,col="red")
text(-3.6,Linf,expression(L[infinity]),xpd=TRUE,col="red",cex=1.25)
@
\end{frame}


\begin{frame}[fragile]
\frametitle{von Bertalanffy Model -- Typical}
<<vbTK, echo=FALSE, out.width='.45\\linewidth'>>=
# plot the vonB curves for same Ks, different Linf
curve(vbT(x,Linf=400,K=0.2,t0=0),from=0,to=15,lwd=3,
      xlab="Age",ylab="Length",ylim=c(0,400))
curve(vbT(x,Linf=250,K=0.2,t0=0),from=0,to=15,lwd=3,col="blue3",add=TRUE)
legend("topleft",c("K=0.2, Linf=400","K=0.2, Linf=250"),lwd=3,col=c("black","blue3"),bty="n")
# plot the vonB curves for different Ks, different Linf
curve(vbT(x,Linf=400,K=0.2,t0=0),from=0,to=15,lwd=3,
      xlab="Age",ylab="Length",ylim=c(0,400))
curve(vbT(x,Linf=500,K=0.125,t0=0),from=0,to=15,lwd=3,col="blue3",add=TRUE)
legend("topleft",c("K=0.2, Linf=400","K=0.125, Linf=500"),lwd=3,col=c("black","blue3"),bty="n")
@
\begin{itemize}[<+->]
  \item $K$ is NOT the growth rate (units are yr$^{-1}$).
  \pause
  \item $K$ does represent how fast $L$ approaches $L_{\infty}$.
  \begin{itemize}
    \item $\frac{log(2)}{K}$ is ``half-life'' (time to reach $\frac{L_{\infty}}{2}$).
  \end{itemize}
\end{itemize}
\end{frame}


%###############################################################################
%###############################################################################
\begin{frame}[fragile, t]
\frametitle{Non-Linear Least-Squares}
\begin{columns}[t]
  \begin{column}{0.5\textwidth}
    \begin{itemize}
      \item von Bertalanffy growth model is non-linear.
      \pause
      \item Non-linear least-squares methods minimize RSS.
    \end{itemize}  
  \end{column}
  \begin{column}{0.5\textwidth}
\begin{center}
\textbf{RSS Surface (side view)}
\end{center}
<<fitMinRSS1, echo=FALSE, fig.align='left', out.width='.95\\linewidth'>>=
# Make some 2-d normal data
x <- seq(-3,3,0.05)
X <- grid2d(x)
z <- dnorm2d(X$x,X$y,rho=0.5)
# rescale z so that the max is 1
z <- z/max(z)
# set some perspectives and colors
theta <- 0 # no twist
phi <- 30 # looking down
d <- 3
clr <- "gray90"
# flip over so that it looks like we are minimizing an RSS -- easy solution example
z <- -1*z
Z <- list(x=x,y=x,z=matrix(z,ncol=length(x)))
par(mar=c(0,0,1,0))
# draw first perspective
persp(Z,theta=theta,phi=phi,col=clr,box=FALSE,axes=FALSE,
      shade=1,border=NA,zlim=c(-1,0),d=d)
@
  \end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile, t]
\frametitle{Non-Linear Least-Squares}
\begin{columns}[t]
  \begin{column}{0.5\textwidth}
\begin{center}
\textbf{RSS Surface (top view)}
\end{center}
<<fitMinRSS2, echo=FALSE, fig.align='left', out.width='.95\\linewidth'>>=
# draw top-down perspective
par(mar=c(0,0,1,0))
res <- persp(Z,theta=theta,phi=90,col=clr,box=FALSE,axes=FALSE,
               shade=1,border=NA,zlim=c(-1,0),d=d)
@
  \end{column}
  \begin{column}{0.5\textwidth} 
    \begin{itemize}[<+->]
      \item No closed-form solution as in linear least-squares.
      \item Non-linear algorithms iteratively ``search'' for the minimum RSS.
      \item Non-linear algorithms require starting values for model parameters.
    \end{itemize}  
  \end{column}
\end{columns}
\end{frame}


\begin{frame}[fragile, t]
\frametitle{Non-Linear Least-Squares}
\begin{columns}[t]
  \begin{column}{0.5\textwidth}
\begin{center}
\textbf{RSS Surface (top view)}
\end{center}
<<fitMinRSS2a, echo=FALSE, fig.align='left', out.width='.95\\linewidth'>>=
# draw top-down perspective
par(mar=c(0,0,1,0))
res <- persp(Z,theta=theta,phi=90,col=clr,box=FALSE,axes=FALSE,
               shade=1,border=NA,zlim=c(-1,0),d=d)
# put a iteration trail on the plot
ptX <- c(10,25,45,55,60.8)
ptY <- c(25,45,56,60,60.8)
zs <- numeric(length(ptX))
for (i in 1:length(ptX)) zs[i] <- Z$z[ptX[i],ptY[i]]
lines(trans3d(Z$x[ptX],Z$y[ptY],zs,pmat=res),type="b",pch=16,col="red")
# put a second iteration trail on the plot
ptX <- c(5,8,15,30,45,55,59,61.2)
ptY <- c(115,115,112,100,85,70,64,61.2)
zs <- numeric(length(ptX))
for (i in 1:length(ptX)) zs[i] <- Z$z[ptX[i],ptY[i]]
lines(trans3d(Z$x[ptX],Z$y[ptY],zs,pmat=res),type="b",pch=16,col="blue3")
@
  \end{column}
  \begin{column}{0.5\textwidth}
    \begin{itemize}
      \item No closed-form solution as in linear least-squares.
      \item Non-linear algorithms iteratively ``search'' for the minimum RSS.
      \item Non-linear algorithms require starting values for model parameters.
    \end{itemize}  
  \end{column}
\end{columns}
\end{frame}


\begin{frame}[t]
\frametitle{Confidence Regions for Parameters}
\begin{itemize}[<+->]
  \item Sampling distribution of parameter estimates tend NOT to be normally distributed.
  \item Thus, usual normal theory is NOT appropriate.
\end{itemize}

\smallskip
\begin{itemize}[<+->]
  \item \textbf{Alternative \#1 -- Profile likelihood method.}
  \begin{enumerate}
    \item Uses $\chi^{2}$ and shape of likelihood function.
  \end{enumerate}
  \smallskip
  \item \textbf{Alternative \#2 -- Bootstrapping.}
  \begin{enumerate}[<+->]
    \item Construct a random sample (with replacement) of $n$ ``cases'' of observed data.
    \item Extract parameters from model fit to this (re)sample.
    \item Repeat first two steps $B$ times.
    \item 95\% CI is values of ordered parameter estimates with 2.5\% of values lesser and 2.5\% of values greater.
  \end{enumerate}
\end{itemize}
\end{frame}


\begin{frame}[fragile, t]
\frametitle{Confidence Regions for Parameters}
<<bootT1, echo=FALSE, message=FALSE, warning=FALSE>>=
### for Linf
# bootstrap CIs
bootT <- nlsBoot(fitT,niter=200)
hist(bootT$coefboot[,"Linf"],breaks=30,xlab="Linf",main="",col="gray90")
with(bootT,plotCI(bootCI["Linf","Median"],grconvertY(0.1,"npc"),li=bootCI["Linf","2.5%"],
                  ui=bootCI["Linf","97.5%"],err="x",add=TRUE,col="black",pch=16,lwd=3))
with(bootT,text(bootCI["Linf",c("2.5%","97.5%")],grconvertY(0.1,"npc"),
                round(bootCI["Linf",c("2.5%","97.5%")],1),pos=3,col="black",cex=1.25,xpd=TRUE))
text(grconvertX(1,"npc"),grconvertY(0.1,"npc"),"Bootstrap",pos=2,col="black",cex=1.25)

### for K
# bootstrap CIs
hist(bootT$coefboot[,"K"],breaks=20,xlab="K",main="",col="gray90")
with(bootT,plotCI(bootCI["K","Median"],grconvertY(0.1,"npc"),li=bootCI["K","2.5%"],
                  ui=bootCI["K","97.5%"],err="x",add=TRUE,col="black",pch=16,lwd=3))
with(bootT,text(bootCI["K",c("2.5%","97.5%")],grconvertY(0.1,"npc"),
                round(bootCI["K",c("2.5%","97.5%")],2),pos=3,col="black",cex=1.25,xpd=TRUE))
@
\end{frame}


\begin{frame}[fragile, t]
\frametitle{Confidence Regions for Parameters}
<<bootT2, echo=FALSE, message=FALSE, cache=TRUE>>=
### for Linf
# bootstrap CIs
hist(bootT$coefboot[,"Linf"],breaks=30,xlab="Linf",main="",col="gray90")
with(bootT,plotCI(bootCI["Linf","Median"],grconvertY(0.1,"npc"),li=bootCI["Linf","2.5%"],
                  ui=bootCI["Linf","97.5%"],err="x",add=TRUE,col="black",pch=16,lwd=3))
with(bootT,text(bootCI["Linf",c("2.5%","97.5%")],grconvertY(0.1,"npc"),
                round(bootCI["Linf",c("2.5%","97.5%")],1),pos=3,col="black",cex=1.25,xpd=TRUE))
text(grconvertX(1,"npc"),grconvertY(0.1,"npc"),"Bootstrap",pos=2,col="black",cex=1.25)
# profile likelihood CIs
tmpP <- confint(fitT)[-3,]
plotCI(coef(fitT)["Linf"],grconvertY(0.3,"npc"),li=tmpP["Linf","2.5%"],
                  ui=tmpP["Linf","97.5%"],err="x",add=TRUE,col="blue3",pch=16,lwd=3)
text(tmpP["Linf",],grconvertY(0.3,"npc"),round(tmpP["Linf",],1),pos=3,col="blue3",cex=1.25,xpd=TRUE)
text(grconvertX(1,"npc"),grconvertY(0.3,"npc"),"Profile LH",pos=2,col="blue3",cex=1.25)
# normal theory CIs
tmpN <- data.frame(sumT$parameters[-3,-c(3,4)])
tmpN$LCI <- tmpN$Estimate-1.96*tmpN$"Std..Error"
tmpN$UCI <- tmpN$Estimate+1.96*tmpN$"Std..Error"
plotCI(tmpN["Linf","Estimate"],grconvertY(0.5,"npc"),li=tmpN["Linf","LCI"],
                  ui=tmpN["Linf","UCI"],err="x",add=TRUE,col="red",pch=16,lwd=3)
text(tmpN["Linf",-c(1,2)],grconvertY(0.5,"npc"),round(tmpN["Linf",-c(1,2)],1),pos=3,col="red",cex=1.25,xpd=TRUE)
text(grconvertX(1,"npc"),grconvertY(0.5,"npc"),"Normal",pos=2,col="red",cex=1.25)

### for K
# bootstrap CIs
hist(bootT$coefboot[,"K"],breaks=20,xlab="K",main="",col="gray90")
with(bootT,plotCI(bootCI["K","Median"],grconvertY(0.1,"npc"),li=bootCI["K","2.5%"],
                  ui=bootCI["K","97.5%"],err="x",add=TRUE,col="black",pch=16,lwd=3))
with(bootT,text(bootCI["K",c("2.5%","97.5%")],grconvertY(0.1,"npc"),
                round(bootCI["K",c("2.5%","97.5%")],2),pos=3,col="black",cex=1.25,xpd=TRUE))
# profile likelihood CIs
plotCI(coef(fitT)["K"],grconvertY(0.3,"npc"),li=tmpP["K","2.5%"],
                  ui=tmpP["K","97.5%"],err="x",add=TRUE,col="blue3",pch=16,lwd=3)
text(tmpP["K",],grconvertY(0.3,"npc"),round(tmpP["K",],2),pos=3,col="blue3",cex=1.25,xpd=TRUE)
# normal theory CIs
plotCI(tmpN["K","Estimate"],grconvertY(0.5,"npc"),li=tmpN["K","LCI"],
                  ui=tmpN["K","UCI"],err="x",add=TRUE,col="red",pch=16,lwd=3)
text(tmpN["K",-c(1,2)],grconvertY(0.5,"npc"),round(tmpN["K",-c(1,2)],2),pos=3,col="red",cex=1.25,xpd=TRUE)
@
\end{frame}


\end{document}